{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import math\n",
    "from stemming.porter2 import stem\n",
    "from data_prep import Doc, parse_docs, parse_query, my_df, avg_length, get_queries, get_folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JM_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_JMLM(coll, q, df):\n",
    "    # Load stopwords from the file\n",
    "    with open('common-english-words.txt', 'r') as stopwords_f: \n",
    "        stop_words = stopwords_f.read().split(',')\n",
    "\n",
    "    JM_LM = {}  # Initializing a dictionary to store the scores for documents\n",
    "    parsed_query = parse_query(q, stop_words)  # Parse the query\n",
    "\n",
    "    # Initialize lambda\n",
    "    ld = 0.4\n",
    "\n",
    "    # Initialize document lengths and collection frequencies\n",
    "    D_len = {}\n",
    "    CF = {}\n",
    "    coll_length = 0\n",
    "    \n",
    "    # For each of the documents in collection\n",
    "    for docID, doc in coll.items():\n",
    "        # Initialize document length with a small non-zero value (Taught in review)\n",
    "        D_len[docID] = 0.5\n",
    "        for term, freq in doc.terms.items():\n",
    "            # Document length is updated\n",
    "            D_len[docID] += freq\n",
    "            # Then the term freq for the collection is updated as well\n",
    "            CF[term] = CF.get(term, 0) + freq\n",
    "            # Meanwhile, can also count the collection length \n",
    "            coll_length += freq\n",
    "\n",
    "    # Ensure all query terms are in the inverted list (CF), if is not then assign a 0\n",
    "    for term in parsed_query:\n",
    "        if term not in CF:\n",
    "            CF[term] = 0\n",
    "\n",
    "    # Calculate JM_LM score for each document\n",
    "    for docID, doc in coll.items():\n",
    "        JM_LM[docID] = 1  # Initialize the score for the document, as we are doing multiplication\n",
    "\n",
    "        for term in parsed_query:  # Each term in the parsed query\n",
    "            fqi = doc.terms.get(term, 0)  # Frequency of the term in the document\n",
    "            cqi = CF[term]  # Frequency of the term in the collection (CF)\n",
    "            JM_LM[docID] *= ((1 - ld) * (fqi / D_len[docID])) + (ld * (cqi / coll_length))  # Update the JM_LM score\n",
    "\n",
    "    return JM_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JMLM(queries, data_path):\n",
    "    curr_path=os.getcwd()\n",
    "    \n",
    "    stopwords_f = open('common-english-words.txt', 'r')\n",
    "    stop_words = stopwords_f.read().split(',')\n",
    "    stopwords_f.close()\n",
    "    \n",
    "    # Create folder\n",
    "    folder_path=curr_path+\"/RankingOutputs\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    for query_id, query in queries.items():\n",
    "        matched_folder=get_folder_name(query_id, data_path)   # Get the name of corresponding collection \n",
    "        for folder_name in os.listdir(data_path):                   \n",
    "            if (folder_name == matched_folder):               # Find corresponding collection name\n",
    "                inputpath=data_path+'/'+folder_name           \n",
    "                coll = parse_docs(stop_words,inputpath)  # Parse the documents in the collection\n",
    "                os.chdir(curr_path)\n",
    "                df=my_df(coll)                            # Get a dictionary of term and document-frequency (df)\n",
    "                ndocs=len(coll)                           # Count number of documents in the collection\n",
    "                file_name=\"JMLM_\"+query_id+\"Ranking.dat\"\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        with open(file_path, \"w\") as writer:\n",
    "            JMLM=my_JMLM(coll, query, df)\n",
    "            query_details = 'For query \"'+query+'\", N:'+str(ndocs)+\"\\n\"\n",
    "            #print(query_details)\n",
    "\n",
    "            for docID, score in sorted(JMLM.items(),key=lambda x: x[1],reverse=True): \n",
    "                details=str(docID)+\" \"+str(score)+\"\\n\"\n",
    "                #print(details)\n",
    "                writer.write(details)\n",
    "\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_path=os.getcwd()\n",
    "data_path = curr_path+'/Data_Collection'\n",
    "queries = get_queries(\"the50Queries.txt\")\n",
    "\n",
    "JMLM(queries, data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
